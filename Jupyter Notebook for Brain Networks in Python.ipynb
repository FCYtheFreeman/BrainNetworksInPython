{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Networks in Python\n",
    "\n",
    "Welcome to a jupyter notebook demonstration of how to use the BrainNetworksinpython repository to ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up\n",
    "\n",
    "   This code prefers Python3 all though (I think) it will still run in 2. \n",
    "   \n",
    "   You will need to clone the BrainNetworksinPython repository\n",
    "\n",
    "You will need the following Python modules installed\n",
    "\n",
    "* [numpy](https://pypi.python.org/pypi/numpy/1.13.0rc1)\n",
    "* [pandas](https://pypi.python.org/pypi/pandas/0.20.1)\n",
    "* [community/python-louvain](https://pypi.python.org/pypi/python-louvain/0.6)\n",
    "* [networkx](https://pypi.python.org/pypi/networkx/1.11)\n",
    "* From the Python Standard Library\n",
    "    * pickle\n",
    "    * os\n",
    "    * sys\n",
    "    * \\_\\_future\\_\\_\n",
    "    * argparse\n",
    "    * textwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running corrmat_from_regionalmeasures\n",
    "\n",
    "We'll start by importing the first of three wrappers. This will process our regional measures data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./WRAPPERS')\n",
    "import corrmat_from_regionalmeasures as cfrm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The function corrmat_from_regionalmeasures function expects three inputs: \n",
    "* the location of the regional measures csv file <!--need description here of what these files mean and what is required of them. Maybe I should have a \"working with your own data section at the end\" -->\n",
    "* the location of the names txt file \n",
    "* the location of where we want to output the resulting file, including the name we want to give it.\n",
    "    * Currently this is set to create an 'cormat_file' in our current working directory. \n",
    "\n",
    "We pass the function a third input names_308_style=True because our names file is in names_308_style. This means it needs to be stripped of 41 subcortical measures named at the beginning of the file. If we used names2, which has been pre stripped, we should not need this as by default names_308_style is set to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "sys.path.append('./exemplary_brains')                                               # Here we are giving directions \n",
    "centroids_file = \"./exemplary_brains/500.centroids.txt\"                             # to our files \n",
    "names_file = \"./exemplary_brains/500.names.txt\"                                     # Feel free to change these to \n",
    "names2_file = \"./exemplary_brains/500.names.2.txt\"                                  # your own data\n",
    "regionalmeasures_file =\"./exemplary_brains/PARC_500aparc_thickness_behavmerge.csv\"  #\n",
    "\n",
    "output_to = os.getcwd()+'/corrmat_file'                                             #\n",
    "\n",
    "\n",
    "cfrm.corrmat_from_regionalmeasures(regionalmeasures_file, names_file, output_to, names_308_style=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running network_analysis_from_corrmat\n",
    "\n",
    "Our second wrapper converts our correlation matrix into a network. It has to generate a number of large random graphs and as such takes a long time to run. \n",
    "\n",
    "It requires the following inputs\n",
    "* The location of the corrmat from regional measures file that we have just created\n",
    "* The location of the names and centroids files\n",
    "* The location and name that we want to give the output file. In this case we are saving it in our current directory and calling it network\\_analysis\n",
    "* an integer cost variable\n",
    "* an integer n_rand variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(303, 304, {'weight': -0.08296}), (303, 305, {'weight': -0.38736}), (303, 306, {'weight': -0.29235}), (303, 307, {'weight': -0.22572}), (304, 305, {'weight': -0.25287}), (304, 306, {'weight': -0.2504}), (304, 307, {'weight': -0.42671}), (305, 306, {'weight': -0.49488}), (305, 307, {'weight': -0.3126}), (306, 307, {'weight': -0.44549})]\n",
      "[(183, 226, {'weight': 0.06611}), (9, 227, {'weight': 0.06717}), (76, 183, {'weight': 0.06824}), (48, 154, {'weight': 0.07155}), (131, 183, {'weight': 0.07201}), (97, 227, {'weight': 0.07446}), (29, 225, {'weight': 0.07504}), (2, 227, {'weight': 0.09313}), (41, 227, {'weight': 0.09399}), (29, 265, {'weight': 0.09966})]\n",
      "        Calculating participation coefficient - may take a little while\n",
      "        Creating 100 random graphs - may take a little while\n"
     ]
    }
   ],
   "source": [
    "# Remember, this is going to take a couple of minutes. It might be worth going to get a cup of tea\n",
    "import network_analysis_from_corrmat as nafc\n",
    "network_analysis = os.getcwd()+'/network_analysis'\n",
    "nafc.network_analysis_from_corrmat(output_to,\n",
    "                                  names,\n",
    "                                  centroids,\n",
    "                                  network_analysis,\n",
    "                                  cost=10,\n",
    "                                  n_rand=100,\n",
    "                                  names_308_style=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising the data\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:whitakerlab]",
   "language": "python",
   "name": "conda-env-whitakerlab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
